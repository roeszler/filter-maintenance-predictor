{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# CI Portfolio Project 5 - Filter Maintenance Predictor 2022\n",
        "## **Data Collection Notebook**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "* Fetch data from Kaggle and save it as raw data.\n",
        "* Inspect the data and save it under outputs/datasets/collection\n",
        "\n",
        "### Inputs\n",
        "\n",
        "*   Kaggle JSON file - the authentication token.\n",
        "\n",
        "### Outputs\n",
        "\n",
        "* Combine Two Datasets: \n",
        "    1. outputs/datasets/collection/**PredictiveMaintenanceTest**.csv\n",
        "    2. outputs/datasets/collection/**PredictiveMaintenanceTrain**.csv\n",
        "    * outputs/datasets/collection/**PredictiveMaintenanceTotal**.csv\n",
        "\n",
        "### Additional Comments\n",
        "* The data is from a publicly accessible Kaggle repo found [here](https://www.kaggle.com/datasets/prognosticshse/preventive-to-predicitve-maintenance) and comes pre-divided into distinctly different Testing and Training data.\n",
        "* For the purposes of the learning context of this project, we are hosting the data in a publicly accessible repo at [GitHub](https://github.com/roeszler/filter-maintenance-predictor).\n",
        "* In the workplace, we would never push data to a public repository due to security exposure it represents."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The notebooks are stored in a subfolder. When running the notebook in the editor, we change the working directory from its current folder to its parent folder.\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "To make the parent of the current directory the new current directory\n",
        "* `os.path.dirname()` = gets the parent directory\n",
        "* `os.chir()` = defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"Current directory set to new location\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Fetch data from Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1. Download a .JSON file (authentication token) from Kaggle and include it in the root directory\n",
        "* kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. Recognize the token in the session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Define the Kaggle dataset, and destination folder and download it.\n",
        "\n",
        "Kaggle url: [/prognosticshse/preventive-to-predicitve-maintenance](https://www.kaggle.com/datasets/prognosticshse/preventive-to-predicitve-maintenance) .\n",
        "* **Note** the misspelling of 'predictive'\n",
        "\n",
        "The following function: \n",
        "* Retrieves and defines the Kaggle dataset\n",
        "* Creates a destination folder folder for the data to be placed\n",
        "* Downloads it to the destination folder\n",
        "* Unzips the downloaded file\n",
        "* Deletes the **.zip** file and unused data\n",
        "* Removes any **kaggle.json** files used to access the dataset on Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "KaggleDatasetPath = 'prognosticshse/preventive-to-predicitve-maintenance'\n",
        "DestinationFolder = 'inputs/datasets/raw'   \n",
        "! kaggle datasets download -d {KaggleDatasetPath} -p {DestinationFolder}\n",
        "\n",
        "! unzip {DestinationFolder}/*.zip -d {DestinationFolder} \\\n",
        "  && rm {DestinationFolder}/*.zip \\\n",
        "  && rm {DestinationFolder}/*.pdf \\\n",
        "  && rm {DestinationFolder}/*.mat \\\n",
        "#   && rm kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Load and Inspect Kaggle data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load Data to Inspect\n",
        "We could combine both datasets, however as they have been included as two sets with slightly different content, we will inspect them each separately."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_test = pd.read_csv(f'inputs/datasets/raw/Test_Data_CSV.csv')\n",
        "df_train = pd.read_csv(f'inputs/datasets/raw/Train_Data_CSV.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### DataFrame Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explore Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### To explore the **Test** dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "pandas_report_test = ProfileReport(df=df_test, minimal=True)\n",
        "pandas_report_test.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main observations of the **Test** Dataset :\n",
        "\n",
        "* There are no missing cells.\n",
        "\n",
        "* Differential Pressure has zero's and has a **reverse exponential** shaped distribution \n",
        "    * This correlates to what we understand. The beginning of each test set will have a period where the filter is clean and the difference in pressure is negligible.\n",
        "    * Subsequently, the measures of distribution (Mean, Median, Mode, Skewness, Kurtosis) correlate to the reverse exponential shape\n",
        "\n",
        "* Most of the **Dust_Feed** was run at 60mm<sup>3</sup>/s\n",
        "    * possibly manipulate data to make the range of test sets more evenly distributed\n",
        "\n",
        "* There is more than three times the amount of A3 Medium Dust observations (47.9%) as there is A2 Fine dust (14.8%), with A4 Course tests (37.3%)\n",
        "    * possibly manipulate data to make the range of test sets more evenly distributed\n",
        "    \n",
        "* The RUL target distribution is right or **positively skewed** at 0.71.\n",
        "    * Confirmed by the **Mean** of **111.48** > **Median** of **93.5**\n",
        "    * An ideal normal distribution has mean, median and mode similar in value and a skewness measure approaching zero\n",
        "    * A measure of the distributions tails; Kurtosis at -0.34 is relatively low in value and negative, indicating few outliers.\n",
        "    * Similar to **differential pressure** This shape is what we expect for a variable that progresses to zero.\n",
        "\n",
        "### Early Conclusions\n",
        "* Further box plot visualization to further investigate this skewness.\n",
        "* We will consider manipulating data at the feature engineering stage to reduce the affect of skewness, like:\n",
        "    * Random Forest Selection (Bagging)\n",
        "    * Logarithmic transformation\n",
        "    * Manipulate the data range to that of test sets more evenly distributed\n",
        "    * Feature Scaling\n",
        "\n",
        "#### Note: \n",
        "This dataset has deliberately had the tails of its observations removed at random points (right censored). This needs to be considered when looking at engineering the distributions. In light of this, depending on our Principal Component Analysis (PCA) a Random Forest Selection (Bagging) may present itself as the preferred method to engineer this set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### To explore the **Train** dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pandas_report_train = ProfileReport(df=df_train, minimal=True)\n",
        "pandas_report_train.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What group do the zeros appear in mostly?"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Main observations of the **Train** Dataset :\n",
        "\n",
        "* There are also no missing cells.\n",
        "\n",
        "* Differential Pressure has zero's and has the same **reverse exponential** shaped distribution as df_test.\n",
        "    * This correlates to what we understand. The beginning of each test set will have a period where the filter is clean and the difference in pressure is negligible.\n",
        "    * Subsequently, the measures of distribution (Mean, Median, Mode, Skewness, Kurtosis) correlate to the same reverse exponential shape\n",
        "\n",
        "\n",
        "* Most of the **Dust_Feed** was ab bit more evenly spread through the data, a 27% from 158.5mm<sup>3</sup>/s to around 20% in feeds between 60mm<sup>3</sup>/s to 118mm<sup>3</sup>/s.\n",
        "    * In a live project, we would check the stakeholders as to possible reasons for this and confirm that it represents typical data seen in practice\n",
        "    * possibly manipulate data to make the range of test sets more evenly distributed\n",
        "\n",
        "\n",
        "* The dust observations maintain A3 Medium Dust as the highest proportion (47.9%), however the portions of A2 Fine dust (28.2%) to A4 Course Dust (23.7%) are approximately the same.\n",
        "    * We would also check this with the stakeholders in a live workplace project\n",
        "    * possibly manipulate data to make the range of test sets more evenly distributed\n",
        "\n",
        "#### Reminder Note: \n",
        "This dataset has deliberately had the tails of its observations removed at random points (right censored). This needs to be considered when looking at engineering the distributions of this dataset. In light of this and further Principal Component Analysis (PCA) a Random Forest Selection (Bagging) may present itself as the preferred method to engineer this set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save the files to an outputs/../collection folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/collection') # create outputs/datasets/collection folder\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "\n",
        "df_train.to_csv(f'outputs/datasets/collection/PredictiveMaintenanceTrain.csv',index=False)\n",
        "df_test.to_csv(f'outputs/datasets/collection/PredictiveMaintenanceTest.csv',index=False)\n",
        "# df_total.to_csv(f'outputs/datasets/collection/PredictiveMaintenanceTotal.csv',index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now push the changes to your GitHub Repo, using the Git commands (git add, git commit, git push)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Conclusions and Next steps"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Conclusions: \n",
        "* Data supplied without missing observations\n",
        "\n",
        "#### Next Steps:\n",
        "* Clean Data\n",
        "    * Create Total dataset\n",
        "    * Extend Data_No references\n",
        "    * Determine Correlations\n",
        "    * Manage Missing Data\n",
        "    * Review Outliers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12 (default, Dec  2 2022, 16:09:02) \n[GCC 9.4.0]"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
